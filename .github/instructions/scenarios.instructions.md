---
applyTo: tests/scenarios/**
---

# Scenario testing

Scenario tests are end-to-end integration tests with realistic configurations and time-frozen states.

## Structure

```
tests/scenarios/
├── test_scenarios.py      # Centralized parameterized test runner
├── conftest.py            # Shared fixtures
├── snapshots/
│   └── test_scenarios.ambr
└── scenario*/
    ├── config.json        # Integration configuration
    └── states.json        # HA state data (includes timestamp)
```

## Auto-discovery

Test runner automatically discovers all `scenario*/` folders using `Path.glob("scenario*/")`.
No registration needed - just create a new folder.

## Scenario files

### config.json

Integration configuration matching the config flow schema:

```json
{
  "elements": {
    "battery": {
      "name": "Home Battery",
      "capacity": 10000,
      "power_limit": 5000
    }
  },
  "connections": []
}
```

### states.json

Home Assistant state data with required `now` timestamp:

```json
{
  "now": "2024-01-15T12:00:00+00:00",
  "states": {
    "sensor.solar_power": {
      "state": "3500",
      "attributes": {
        "unit_of_measurement": "W"
      }
    }
  }
}
```

## Time freezing

The test runner extracts the `now` timestamp from `states.json` and uses freezegun for deterministic results.
All datetime operations during the test see this frozen time.

## Running scenarios

- Use `-k scenario_name` to run specific scenarios
- Use `--snapshot-update` to regenerate snapshots

## Creating new scenarios

1. Create new folder: `tests/scenarios/scenario_name/`
2. Add `config.json` with integration configuration
3. Add `states.json` with HA state data (must include `now` timestamp)
4. Run tests - auto-discovered automatically
5. Review and commit generated snapshots

## Snapshot format

All scenarios share a single snapshot file using syrupy JSON extension.
Snapshots capture:

- Optimization results
- Sensor states
- Element configurations

## Working with outputs.json

Each scenario has an `outputs.json` file containing the expected sensor states after optimization.
These files are generated by the test runner and can be large (1000+ lines).

### Structure

```json
{
  "sensor.battery_charge_power": {
    "state": "5.0",
    "attributes": {
      "element_name": "Battery",
      "element_type": "battery",
      "forecast": [
        {
          "start": "2024-01-15T12:00:00+00:00",
          "end": "2024-01-15T12:05:00+00:00",
          "value": 5.0
        },
        {
          "start": "2024-01-15T12:05:00+00:00",
          "end": "2024-01-15T12:10:00+00:00",
          "value": 3.2
        }
      ],
      "friendly_name": "Charge Power",
      "state_class": "measurement",
      "unit_of_measurement": "kW"
    }
  }
}
```

### Common jq queries

List all entity IDs:

```bash
jq -r 'keys[]' tests/scenarios/scenario1/outputs.json
```

Count entities:

```bash
jq 'keys | length' tests/scenarios/scenario1/outputs.json
```

Get friendly names for all sensors:

```bash
jq -r 'to_entries[] | "\(.key): \(.value.attributes.friendly_name)"' tests/scenarios/scenario1/outputs.json
```

Filter sensors by element type (e.g., battery):

```bash
jq -r 'to_entries[] | select(.value.attributes.element_type == "battery") | .key' tests/scenarios/scenario1/outputs.json
```

Get state values for a specific sensor:

```bash
jq '.["sensor.battery_charge_power"].state' tests/scenarios/scenario1/outputs.json
```

Extract forecast array for a sensor:

```bash
jq '.["sensor.battery_charge_power"].attributes.forecast' tests/scenarios/scenario1/outputs.json
```

Get first forecast value for all battery sensors:

```bash
jq -r 'to_entries[] | select(.value.attributes.element_type == "battery") | "\(.key): \(.value.attributes.forecast[0].value)"' tests/scenarios/scenario1/outputs.json
```

Find sensors with specific unit:

```bash
jq -r 'to_entries[] | select(.value.attributes.unit_of_measurement == "kW") | .key' tests/scenarios/scenario1/outputs.json
```

Compare a specific value across scenarios:

```bash
for f in tests/scenarios/scenario*/outputs.json; do echo "=== $f ===" && jq '.["sensor.battery_state_of_charge"].state' "$f"; done
```

### When to regenerate snapshots

Regenerate snapshots when:

- Translation keys or display names change
- Sensor output structure changes
- Adding new sensors or elements
- Fixing optimization bugs

Use `--snapshot-update` flag:

```bash
uv run pytest tests/scenarios/ -m scenario --snapshot-update
```

Always review the diff before committing updated snapshots.

## Debugging scenarios

Use the visualization tools in `tests/scenarios/visualization.py` to generate charts of optimization results for debugging.
